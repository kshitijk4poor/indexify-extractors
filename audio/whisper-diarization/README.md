# Whisper Diarization Extractor

### Kindly use asrdiarization.asr_extractor:ASRExtractor instead of this for easier setup and better results

This extractor uses Whisper ASR and Voice Activity Detection (VAD) to identify the speaker for each sentence in the transcription generated by Whisper.

A given audio file will go through the following steps:

1. Voice Extraction: Isolate voices from background noise to improve the clarity of the speaker's voice.
2. Transcription with Whisper: Use Whisper technology to transcribe the speech, converting audio into text.
3. Timestamp Alignment with WhisperX: Correct and align the timestamps for each spoken word using WhisperX to minimize timing discrepancies.
4. Voice Activity Detection with MarbleNet: Employ MarbleNet to detect active speech segments and remove silences from the audio.
5. Speaker Embedding with TitaNet: Utilize TitaNet to analyze voice characteristics and identify unique speakers in the audio.
6. Speaker Association: Associate the identified speakers with the correct segments and words in the transcription based on the timestamps generated by WhisperX.
7. Time Shift Compensation: Apply punctuation models to adjust for minor time shifts and ensure accurate speaker identification throughout the transcript.

### Example

### Install requirements on mac / cpu
```pip install --no-deps -r requirements.Darwin.txt```

### Install requirements for Linux on GPUs
You might need to run the following script before running the extractor on Linux with CUDA -
```
export LD_LIBRARY_PATH=`python3 -c 'import os; import nvidia.cublas.lib; import nvidia.cudnn.lib; print(os.path.dirname(nvidia.cublas.lib.__file__) + ":" + os.path.dirname(nvidia.cudnn.lib.__file__))'`
```

##### input params:
 language: Optional[str] = None
 stemming: bool = True
 batch_size: int = 0
 model: str = "distil-medium.en"
 supress_numerals: bool = False
 device: str = "cuda" if torch.cuda.is_available() else "cpu"

##### input content audio/mpeg
short-podcast-clip.mp3

##### output json content:
```json
[
  {
    "speaker": "Speaker 1",
    "start_time": 0,
    "end_time": 1.48,
    "text": "Where does that come from? "
  },
  {
    "speaker": "Speaker 1",
    "start_time": 1.68,
    "end_time": 4.078,
    "text": "Oh, just when he wasn't hate, we just, we don't hate right now. "
  },
  {
    "speaker": "Speaker 1",
    "start_time": 4.561,
    "end_time": 6.94,
    "text": "But no, really, like, it's not a large sample side. "
  },
  {
    "speaker": "Speaker 1",
    "start_time": 7.08,
    "end_time": 9.58,
    "text": "James Hardin didn't play at all in the preseason. "
  },
  {
    "speaker": "Speaker 0",
    "start_time": 9.88,
    "end_time": 11.839,
    "text": "Kenny, stop making excuses for that, man, no. "
  },
  {
    "speaker": "Speaker 1",
    "start_time": 12.2,
    "end_time": 15.82,
    "text": "And we evaluate them 20 games in, and you'll tell what they are. "
  },
  {
    "speaker": "Speaker 0",
    "start_time": 15.96,
    "end_time": 19.151,
    "text": "A team with kawai, James, Russell with the role. "
  }
]
```


### Acknowledgements
This extractor is based on the work of Mahmoud Ashraf's GitHub project [whisper-diarization](https://github.com/MahmoudAshraf97/whisper-diarization).

Models used are [OpenAI's Whisper](https://github.com/openai/whisper) , [Faster Whisper](https://github.com/guillaumekln/faster-whisper) , [Nvidia NeMo](https://github.com/NVIDIA/NeMo) , and [Facebook's Demucs](https://github.com/facebookresearch/demucs)
